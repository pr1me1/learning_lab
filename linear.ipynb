{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-04T05:37:29.211613626Z",
     "start_time": "2026-02-04T05:37:29.202480063Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n"
   ],
   "outputs": [],
   "execution_count": 111
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:37:29.241997160Z",
     "start_time": "2026-02-04T05:37:29.212610201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ],
   "id": "474c90a6a0a88e5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 112
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:37:29.263625041Z",
     "start_time": "2026-02-04T05:37:29.247556222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "weight = 0.5\n",
    "bias = 1.8\n",
    "\n",
    "x = torch.linspace(0, 6, 300).reshape(-1, 1)\n",
    "x"
   ],
   "id": "30c123c4d0cb6d41",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000],\n",
       "        [0.0201],\n",
       "        [0.0401],\n",
       "        [0.0602],\n",
       "        [0.0803],\n",
       "        [0.1003],\n",
       "        [0.1204],\n",
       "        [0.1405],\n",
       "        [0.1605],\n",
       "        [0.1806],\n",
       "        [0.2007],\n",
       "        [0.2207],\n",
       "        [0.2408],\n",
       "        [0.2609],\n",
       "        [0.2809],\n",
       "        [0.3010],\n",
       "        [0.3211],\n",
       "        [0.3411],\n",
       "        [0.3612],\n",
       "        [0.3813],\n",
       "        [0.4013],\n",
       "        [0.4214],\n",
       "        [0.4415],\n",
       "        [0.4615],\n",
       "        [0.4816],\n",
       "        [0.5017],\n",
       "        [0.5217],\n",
       "        [0.5418],\n",
       "        [0.5619],\n",
       "        [0.5819],\n",
       "        [0.6020],\n",
       "        [0.6221],\n",
       "        [0.6421],\n",
       "        [0.6622],\n",
       "        [0.6823],\n",
       "        [0.7023],\n",
       "        [0.7224],\n",
       "        [0.7425],\n",
       "        [0.7625],\n",
       "        [0.7826],\n",
       "        [0.8027],\n",
       "        [0.8227],\n",
       "        [0.8428],\n",
       "        [0.8629],\n",
       "        [0.8829],\n",
       "        [0.9030],\n",
       "        [0.9231],\n",
       "        [0.9431],\n",
       "        [0.9632],\n",
       "        [0.9833],\n",
       "        [1.0033],\n",
       "        [1.0234],\n",
       "        [1.0435],\n",
       "        [1.0635],\n",
       "        [1.0836],\n",
       "        [1.1037],\n",
       "        [1.1237],\n",
       "        [1.1438],\n",
       "        [1.1639],\n",
       "        [1.1839],\n",
       "        [1.2040],\n",
       "        [1.2241],\n",
       "        [1.2441],\n",
       "        [1.2642],\n",
       "        [1.2843],\n",
       "        [1.3043],\n",
       "        [1.3244],\n",
       "        [1.3445],\n",
       "        [1.3645],\n",
       "        [1.3846],\n",
       "        [1.4047],\n",
       "        [1.4247],\n",
       "        [1.4448],\n",
       "        [1.4649],\n",
       "        [1.4849],\n",
       "        [1.5050],\n",
       "        [1.5251],\n",
       "        [1.5452],\n",
       "        [1.5652],\n",
       "        [1.5853],\n",
       "        [1.6054],\n",
       "        [1.6254],\n",
       "        [1.6455],\n",
       "        [1.6656],\n",
       "        [1.6856],\n",
       "        [1.7057],\n",
       "        [1.7258],\n",
       "        [1.7458],\n",
       "        [1.7659],\n",
       "        [1.7860],\n",
       "        [1.8060],\n",
       "        [1.8261],\n",
       "        [1.8462],\n",
       "        [1.8662],\n",
       "        [1.8863],\n",
       "        [1.9064],\n",
       "        [1.9264],\n",
       "        [1.9465],\n",
       "        [1.9666],\n",
       "        [1.9866],\n",
       "        [2.0067],\n",
       "        [2.0268],\n",
       "        [2.0468],\n",
       "        [2.0669],\n",
       "        [2.0870],\n",
       "        [2.1070],\n",
       "        [2.1271],\n",
       "        [2.1472],\n",
       "        [2.1672],\n",
       "        [2.1873],\n",
       "        [2.2074],\n",
       "        [2.2274],\n",
       "        [2.2475],\n",
       "        [2.2676],\n",
       "        [2.2876],\n",
       "        [2.3077],\n",
       "        [2.3278],\n",
       "        [2.3478],\n",
       "        [2.3679],\n",
       "        [2.3880],\n",
       "        [2.4080],\n",
       "        [2.4281],\n",
       "        [2.4482],\n",
       "        [2.4682],\n",
       "        [2.4883],\n",
       "        [2.5084],\n",
       "        [2.5284],\n",
       "        [2.5485],\n",
       "        [2.5686],\n",
       "        [2.5886],\n",
       "        [2.6087],\n",
       "        [2.6288],\n",
       "        [2.6488],\n",
       "        [2.6689],\n",
       "        [2.6890],\n",
       "        [2.7090],\n",
       "        [2.7291],\n",
       "        [2.7492],\n",
       "        [2.7692],\n",
       "        [2.7893],\n",
       "        [2.8094],\n",
       "        [2.8294],\n",
       "        [2.8495],\n",
       "        [2.8696],\n",
       "        [2.8896],\n",
       "        [2.9097],\n",
       "        [2.9298],\n",
       "        [2.9498],\n",
       "        [2.9699],\n",
       "        [2.9900],\n",
       "        [3.0100],\n",
       "        [3.0301],\n",
       "        [3.0502],\n",
       "        [3.0702],\n",
       "        [3.0903],\n",
       "        [3.1104],\n",
       "        [3.1304],\n",
       "        [3.1505],\n",
       "        [3.1706],\n",
       "        [3.1906],\n",
       "        [3.2107],\n",
       "        [3.2308],\n",
       "        [3.2508],\n",
       "        [3.2709],\n",
       "        [3.2910],\n",
       "        [3.3110],\n",
       "        [3.3311],\n",
       "        [3.3512],\n",
       "        [3.3712],\n",
       "        [3.3913],\n",
       "        [3.4114],\n",
       "        [3.4314],\n",
       "        [3.4515],\n",
       "        [3.4716],\n",
       "        [3.4916],\n",
       "        [3.5117],\n",
       "        [3.5318],\n",
       "        [3.5518],\n",
       "        [3.5719],\n",
       "        [3.5920],\n",
       "        [3.6120],\n",
       "        [3.6321],\n",
       "        [3.6522],\n",
       "        [3.6722],\n",
       "        [3.6923],\n",
       "        [3.7124],\n",
       "        [3.7324],\n",
       "        [3.7525],\n",
       "        [3.7726],\n",
       "        [3.7926],\n",
       "        [3.8127],\n",
       "        [3.8328],\n",
       "        [3.8528],\n",
       "        [3.8729],\n",
       "        [3.8930],\n",
       "        [3.9130],\n",
       "        [3.9331],\n",
       "        [3.9532],\n",
       "        [3.9732],\n",
       "        [3.9933],\n",
       "        [4.0134],\n",
       "        [4.0334],\n",
       "        [4.0535],\n",
       "        [4.0736],\n",
       "        [4.0936],\n",
       "        [4.1137],\n",
       "        [4.1338],\n",
       "        [4.1538],\n",
       "        [4.1739],\n",
       "        [4.1940],\n",
       "        [4.2140],\n",
       "        [4.2341],\n",
       "        [4.2542],\n",
       "        [4.2742],\n",
       "        [4.2943],\n",
       "        [4.3144],\n",
       "        [4.3344],\n",
       "        [4.3545],\n",
       "        [4.3746],\n",
       "        [4.3946],\n",
       "        [4.4147],\n",
       "        [4.4348],\n",
       "        [4.4548],\n",
       "        [4.4749],\n",
       "        [4.4950],\n",
       "        [4.5151],\n",
       "        [4.5351],\n",
       "        [4.5552],\n",
       "        [4.5753],\n",
       "        [4.5953],\n",
       "        [4.6154],\n",
       "        [4.6355],\n",
       "        [4.6555],\n",
       "        [4.6756],\n",
       "        [4.6957],\n",
       "        [4.7157],\n",
       "        [4.7358],\n",
       "        [4.7559],\n",
       "        [4.7759],\n",
       "        [4.7960],\n",
       "        [4.8161],\n",
       "        [4.8361],\n",
       "        [4.8562],\n",
       "        [4.8763],\n",
       "        [4.8963],\n",
       "        [4.9164],\n",
       "        [4.9365],\n",
       "        [4.9565],\n",
       "        [4.9766],\n",
       "        [4.9967],\n",
       "        [5.0167],\n",
       "        [5.0368],\n",
       "        [5.0569],\n",
       "        [5.0769],\n",
       "        [5.0970],\n",
       "        [5.1171],\n",
       "        [5.1371],\n",
       "        [5.1572],\n",
       "        [5.1773],\n",
       "        [5.1973],\n",
       "        [5.2174],\n",
       "        [5.2375],\n",
       "        [5.2575],\n",
       "        [5.2776],\n",
       "        [5.2977],\n",
       "        [5.3177],\n",
       "        [5.3378],\n",
       "        [5.3579],\n",
       "        [5.3779],\n",
       "        [5.3980],\n",
       "        [5.4181],\n",
       "        [5.4381],\n",
       "        [5.4582],\n",
       "        [5.4783],\n",
       "        [5.4983],\n",
       "        [5.5184],\n",
       "        [5.5385],\n",
       "        [5.5585],\n",
       "        [5.5786],\n",
       "        [5.5987],\n",
       "        [5.6187],\n",
       "        [5.6388],\n",
       "        [5.6589],\n",
       "        [5.6789],\n",
       "        [5.6990],\n",
       "        [5.7191],\n",
       "        [5.7391],\n",
       "        [5.7592],\n",
       "        [5.7793],\n",
       "        [5.7993],\n",
       "        [5.8194],\n",
       "        [5.8395],\n",
       "        [5.8595],\n",
       "        [5.8796],\n",
       "        [5.8997],\n",
       "        [5.9197],\n",
       "        [5.9398],\n",
       "        [5.9599],\n",
       "        [5.9799],\n",
       "        [6.0000]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 113
  },
  {
   "metadata": {
    "ExecuteTime": {
     "start_time": "2026-02-04T05:37:29.289248771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_noiseless = weight * x + bias\n",
    "\n",
    "noise_lev = 0.09\n",
    "noise = torch.rand_like(y_noiseless) * noise_lev\n",
    "\n",
    "y = y_noiseless + noise\n",
    "\n",
    "indices = torch.randperm(x.size(0))\n",
    "\n",
    "x = x[indices]\n",
    "y = y[indices]"
   ],
   "id": "1a1319171913f38f",
   "outputs": [],
   "execution_count": 114
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_split = int(0.2 * len(x))\n",
    "\n",
    "x_train, y_train = x[test_split:], y[test_split:]\n",
    "x_test, y_test = x[:test_split], y[:test_split]"
   ],
   "id": "5aa4440223ace4fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_predictions(\n",
    "        train_data=x_train,\n",
    "        test_data=x_test,\n",
    "        train_labels=y_train,\n",
    "        test_labels=y_test,\n",
    "        predictions=None\n",
    "):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(train_data, train_labels, s=4, c=\"b\", label=\"training data\")\n",
    "    plt.scatter(test_data, test_labels, s=4, c=\"r\", label=\"testing data\")\n",
    "\n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, s=4, c=\"g\", label=\"predictions\")\n",
    "\n",
    "    plt.legend(prop={'size': 10})"
   ],
   "id": "bb015af552b12f15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_predictions()",
   "id": "9a09d1f2b91e022e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.weight = nn.Parameter(torch.randn(1, dtype=torch.float32, requires_grad=True))\n",
    "        # self.bias = nn.Parameter(torch.randn(1, dtype=torch.float32, requires_grad=True))\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear(x)\n",
    "        # return self.weight * x + self.bias"
   ],
   "id": "855297f3a8f0a2a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = LinearModel()\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ],
   "id": "23179f0e93bd9973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "epoch_counts = []\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "\n",
    "    train_pred = model(x_train)\n",
    "    train_loss = loss_fn(train_pred, y_train)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        test_pred = model(x_test)\n",
    "        test_loss = loss_fn(test_pred, y_test)\n",
    "\n",
    "        if epoch % 20 == 0:\n",
    "            epoch_counts.append(epoch)\n",
    "            train_losses.append(train_loss.detach().numpy())\n",
    "            test_losses.append(test_loss.detach().numpy())\n",
    "            print(f\"Epoch: {epoch} | MAE Train Loss: {train_loss} | MAE Test Loss: {test_loss} \")"
   ],
   "id": "63f4a1dcf47df49e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(epoch_counts, train_losses, label=\"Train Loss\")\n",
    "plt.plot(epoch_counts, test_losses, label=\"Test Loss\")\n",
    "plt.title(\"Train vs Test loss graph\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ],
   "id": "16edea3b30062296",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    predictions = model(x_test)\n",
    "\n",
    "plot_predictions(predictions=predictions)"
   ],
   "id": "71b2615ea3b043e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:40:48.459275120Z",
     "start_time": "2026-02-04T05:40:48.440216685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_NAME = \"linear.pth\"\n",
    "\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)"
   ],
   "id": "6eca17bb1ffd5ec4",
   "outputs": [],
   "execution_count": 132
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:41:51.303262182Z",
     "start_time": "2026-02-04T05:41:51.276209607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "linear_model = LinearModel()\n",
    "linear_model.load_state_dict(torch.load(MODEL_SAVE_PATH))"
   ],
   "id": "1b6f791370ec6a6b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-04T05:42:14.848280633Z",
     "start_time": "2026-02-04T05:42:14.824224914Z"
    }
   },
   "cell_type": "code",
   "source": "list(linear_model.parameters())",
   "id": "674ad63807ea488f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[0.5192]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.7700], requires_grad=True)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3079f28ca2ce2ea8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
