{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-09T12:03:10.461532271Z",
     "start_time": "2026-02-09T12:03:08.361365251Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "torch.__version__"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0+cu128'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T12:03:10.651362586Z",
     "start_time": "2026-02-09T12:03:10.466789444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ],
   "id": "1e2c14b5bac5c226",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T12:03:10.716944669Z",
     "start_time": "2026-02-09T12:03:10.653986085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from torchvision import datasets, transforms\n",
    "#\n",
    "# train_set = datasets.Food101(\n",
    "#     transform=transforms.ToTensor(),\n",
    "#     root=\"./data\",\n",
    "#     download=True,\n",
    "#     split=\"train\"\n",
    "# )\n",
    "#\n",
    "# test_set = datasets.Food101(\n",
    "#     transform=transforms.ToTensor(),\n",
    "#     root=\"./data\",\n",
    "#     download=True,\n",
    "#     split=\"test\"\n",
    "# )\n",
    "#\n",
    "# len(train_set), len(test_set)\n",
    "\n",
    "\"\"\"So i can download and use it but i wont because it is too much. its size is slightly above from 5GB. and downloading and training such size of data is not good for learning i think\"\"\""
   ],
   "id": "edd0ac92a4d536f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So i can download and use it but i wont because it is too much. its size is slightly above from 5GB. and downloading and training such size of data is not good for learning i think'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T12:03:20.726550458Z",
     "start_time": "2026-02-09T12:03:10.718611175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path(\"./data\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "zip_path = data_path / \"pizza_steak_sushi.zip\"\n",
    "\n",
    "if image_path.is_dir():\n",
    "    print(f\"{image_path} directory exists\")\n",
    "else:\n",
    "    print(f\"Did not find {image_path} directory, creating one...\")\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    response = requests.get(\n",
    "        \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\"\n",
    "    )\n",
    "    print(\"Downloading pizza, steak, sushi data...\")\n",
    "\n",
    "    with open(zip_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        print(\"Extracting pizza, sushi, steak data...\")\n",
    "        zip_ref.extractall(image_path)"
   ],
   "id": "3d9bb89f5241647c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not find data/pizza_steak_sushi directory, creating one...\n",
      "Downloading pizza, steak, sushi data...\n",
      "Extracting pizza, sushi, steak data...\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T12:03:20.948312736Z",
     "start_time": "2026-02-09T12:03:20.827507757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def walk_through_dir(dir_path: Path):\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "\n",
    "\n",
    "walk_through_dir(image_path)"
   ],
   "id": "ddfbc000e303648d",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mNameError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 6\u001B[39m\n\u001B[32m      2\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m dirpath, dirnames, filenames \u001B[38;5;129;01min\u001B[39;00m os.walk(dir_path):\n\u001B[32m      3\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThere are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(dirnames)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m directories and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(filenames)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m images in \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m6\u001B[39m \u001B[43mwalk_through_dir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 2\u001B[39m, in \u001B[36mwalk_through_dir\u001B[39m\u001B[34m(dir_path)\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwalk_through_dir\u001B[39m(dir_path: Path):\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m dirpath, dirnames, filenames \u001B[38;5;129;01min\u001B[39;00m \u001B[43mos\u001B[49m.walk(dir_path):\n\u001B[32m      3\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThere are \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(dirnames)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m directories and \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(filenames)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m images in \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdirpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mNameError\u001B[39m: name 'os' is not defined"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ],
   "id": "3721eaa640bcfa68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "random.seed(42)\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "random_image_path = random.choice(image_path_list)\n",
    "image_class = random_image_path.parent.stem\n",
    "\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image height: {img.height}\")\n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ],
   "id": "e5f9ba0f25ab2b80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_as_array = np.asarray(img)\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]\")\n",
    "plt.axis(False);"
   ],
   "id": "84987ca83f4ccc92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from torchvision import transforms",
   "id": "5e1fbbb94f313061",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.AutoAugment(),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ],
   "id": "4b4cfc7e7b66aa41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_transformed_images(image_path, transform, n=3, seed=42):\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_path, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1, 2)\n",
    "            ax[0].imshow(f)\n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(\"off\")\n",
    "\n",
    "            transformed_image = transform(f).permute(1, 2, 0)\n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(\"off\")\n",
    "\n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)"
   ],
   "id": "f10fb64a65d65e9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_transformed_images(image_path_list, data_transform, n=5, seed=43)",
   "id": "a921c6fed85e98ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torchvision import datasets\n",
    "\n",
    "train_set = datasets.ImageFolder(\n",
    "    root=train_dir,\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "test_set = datasets.ImageFolder(\n",
    "    root=test_dir,\n",
    "    transform=data_transform,\n",
    ")\n",
    "\n",
    "train_set, test_set, len(train_set), len(test_set)"
   ],
   "id": "287a66beba42fa8b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classes = train_set.classes\n",
    "classes"
   ],
   "id": "ab819f49c8f3a12b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "classes_dict = train_set.class_to_idx\n",
    "classes_dict"
   ],
   "id": "21a66cd21a981315",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img, label = train_set[0][0], train_set[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ],
   "id": "f8c4f25e2ba832b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img_permute = img.permute(1, 2, 0)\n",
    "\n",
    "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.axis(\"off\")\n",
    "plt.title(classes[label], fontsize=14);"
   ],
   "id": "2f084fd80c599ca2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=2,\n",
    "    shuffle=True,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=4,\n",
    "    num_workers=2,\n",
    "    shuffle=False,\n",
    ")"
   ],
   "id": "61032d1999ce3002",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "img, label = next(iter(train_loader))\n",
    "img.shape, label.shape"
   ],
   "id": "ca2156cf36952d37",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### Custom dataset",
   "id": "8b79d399e05d408f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "from PIL import Image"
   ],
   "id": "d14fc5a76a71880",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def find_classes(dir: Path):\n",
    "    class_names = sorted(entry.name for entry in os.scandir(dir) if entry.is_dir())\n",
    "    if not class_names:\n",
    "        raise FileNotFoundError(f\"No classes found in {dir}\")\n",
    "\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(class_names)}\n",
    "    return class_names, class_to_idx"
   ],
   "id": "ad385b4221603a0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "find_classes(train_dir)",
   "id": "fa87cf1869c3ec5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T12:06:41.016819138Z",
     "start_time": "2026-02-09T12:06:40.932418310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ImageFolderCustom(Dataset):\n",
    "    def __init__(self, target_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.paths = list(Path(target_dir).glob(\"*/*.jpg\"))\n",
    "        self.classes, self.class_to_idx = find_classes(target_dir)\n",
    "\n",
    "    def load_image(self, index: int):\n",
    "        path = self.paths[index]\n",
    "        return Image.open(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        img = self.load_image(index)\n",
    "        class_name = self.paths[index].parent.name\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx\n",
    "        else:\n",
    "            return img, class_idx"
   ],
   "id": "deeb7d166e350329",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transformer = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ],
   "id": "3030b8a458f85bfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "train_set_custom = ImageFolderCustom(train_dir, train_transformer)\n",
    "test_set_custom = ImageFolderCustom(test_dir, test_transformer)\n",
    "\n",
    "train_set_custom, test_set_custom"
   ],
   "id": "b0d8e27f24cdc98c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_set_custom.classes",
   "id": "658cae81c39d03f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "train_set_custom.class_to_idx",
   "id": "4e4b2f385000b864",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fb414db0f06db8ad",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
