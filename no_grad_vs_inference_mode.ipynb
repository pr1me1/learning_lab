{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:00.625853487Z",
     "start_time": "2026-02-06T10:03:59.063809991Z"
    }
   },
   "source": "import torch",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:00.689865742Z",
     "start_time": "2026-02-06T10:04:00.627482803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x = torch.tensor([1.], requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    y = x * 2\n",
    "y.requires_grad"
   ],
   "id": "ae25d28f2779006",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:00.750251249Z",
     "start_time": "2026-02-06T10:04:00.693004591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "z = doubler(x)\n",
    "z.requires_grad"
   ],
   "id": "ce820ec13d50405e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:00.810503075Z",
     "start_time": "2026-02-06T10:04:00.753482325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def doubler(x):\n",
    "    return x * 2\n",
    "\n",
    "\n",
    "z = doubler(x)\n",
    "z.requires_grad"
   ],
   "id": "a66d9136df3350e9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:00.872668542Z",
     "start_time": "2026-02-06T10:04:00.813449436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def tripler(x):\n",
    "    return x * 3\n",
    "\n",
    "\n",
    "z = tripler(x)\n",
    "z.requires_grad"
   ],
   "id": "993b46d7c01ebfbe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:00.933391543Z",
     "start_time": "2026-02-06T10:04:00.876657072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(1, 2, 3, requires_grad=True)\n",
    "with torch.inference_mode():\n",
    "    y = x * x\n",
    "y.requires_grad"
   ],
   "id": "81d967a0e763b33b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:00.990325451Z",
     "start_time": "2026-02-06T10:04:00.934970723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.inference_mode()\n",
    "def func(x):\n",
    "    return x * x\n",
    "\n",
    "\n",
    "out = func(x)\n",
    "out.requires_grad"
   ],
   "id": "40f628307ee9e36a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:02.516288225Z",
     "start_time": "2026-02-06T10:04:00.992420574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "model = resnet50().to(\"cuda\")\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224).to(\"cuda\")\n",
    "\n",
    "model.train()\n",
    "output_train = model(dummy_input)"
   ],
   "id": "abe6d15f79bc702c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:03.387055337Z",
     "start_time": "2026-02-06T10:04:02.987241930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "        profile_memory=True,\n",
    "        record_shapes=True\n",
    ") as prof_no_grad:\n",
    "    with record_function(\"no_grad_inference\"):\n",
    "        with torch.no_grad():\n",
    "            _ = model(dummy_input)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(\n",
    "    prof_no_grad.key_averages()\n",
    "    .table(sort_by=\"self_cuda_memory_usage\", row_limit=10)\n",
    ")\n"
   ],
   "id": "7a6cb8043bf4536f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         1.88%     544.198us         1.88%     544.198us       2.054us       0.000us         0.00%       0.000us       0.000us           0 B           0 B      42.88 MB      42.88 MB           265  \n",
      "                                aten::cudnn_convolution        10.70%       3.105ms        51.50%      14.940ms     281.894us       7.283ms        63.31%       7.408ms     139.779us           0 B           0 B      42.58 MB      42.58 MB            53  \n",
      "                          aten::max_pool2d_with_indices         0.06%      17.732us         0.08%      22.377us      22.377us      54.080us         0.47%      54.080us      54.080us           0 B           0 B       2.39 MB       2.39 MB             1  \n",
      "                                             aten::mean         0.05%      15.410us         0.07%      20.285us      20.285us      12.063us         0.10%      12.063us      12.063us           0 B           0 B       8.00 KB       8.00 KB             1  \n",
      "                                            aten::addmm         0.16%      45.758us         0.24%      69.338us      69.338us      55.614us         0.48%      55.614us      55.614us           0 B           0 B       4.00 KB       4.00 KB             1  \n",
      "                                           aten::conv2d         0.28%      82.563us        53.26%      15.452ms     291.542us       0.000us         0.00%       7.408ms     139.779us           0 B           0 B      42.58 MB           0 B            53  \n",
      "                                      aten::convolution         0.48%     140.570us        52.98%      15.369ms     289.985us       0.000us         0.00%       7.408ms     139.779us           0 B           0 B      42.58 MB           0 B            53  \n",
      "                                     aten::_convolution         0.99%     288.224us        52.49%      15.229ms     287.332us       0.000us         0.00%       7.408ms     139.779us           0 B           0 B      42.58 MB           0 B            53  \n",
      "                                Activity Buffer Request        38.15%      11.067ms        38.15%      11.067ms      11.067ms     125.152us         1.09%     125.152us     125.152us           0 B           0 B           0 B           0 B             1  \n",
      "                                       cudaLaunchKernel         2.79%     808.544us         2.79%     808.544us       3.183us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           254  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 29.012ms\n",
      "Self CUDA time total: 11.504ms\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/primel/PycharmProjects/pytorch/.venv/lib/python3.13/site-packages/torch/profiler/profiler.py:217: UserWarning: Warning: Profiler clears events at the end of each cycle.Only events from the current cycle will be reported.To keep events across cycles, set acc_events=True.\n",
      "  _warn_once(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:03.571303543Z",
     "start_time": "2026-02-06T10:04:03.444827918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.cuda.synchronize()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "with profile(\n",
    "        activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "        profile_memory=True,\n",
    "        record_shapes=True\n",
    ") as prof_infer:\n",
    "    with record_function(\"inference_mode\"):\n",
    "        with torch.inference_mode():\n",
    "            _ = model(dummy_input)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(\n",
    "    prof_infer.key_averages()\n",
    "    .table(sort_by=\"self_cuda_memory_usage\", row_limit=10)\n",
    ")\n"
   ],
   "id": "65df22e1f0536e24",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                            aten::empty         6.03%       1.452ms         6.03%       1.452ms       5.481us       0.000us         0.00%       0.000us       0.000us           0 B           0 B      42.88 MB      42.88 MB           265  \n",
      "                                aten::cudnn_convolution        11.70%       2.817ms        37.92%       9.126ms     172.181us       7.253ms        63.23%       7.378ms     139.211us           0 B           0 B      42.58 MB      42.58 MB            53  \n",
      "                          aten::max_pool2d_with_indices         0.11%      26.929us         0.16%      38.372us      38.372us      53.664us         0.47%      53.664us      53.664us           0 B           0 B       2.39 MB       2.39 MB             1  \n",
      "                                             aten::mean         0.10%      25.159us         0.15%      35.110us      35.110us      12.064us         0.11%      12.064us      12.064us           0 B           0 B       8.00 KB       8.00 KB             1  \n",
      "                                            aten::addmm         0.44%     105.495us         1.66%     399.023us     399.023us      55.232us         0.48%      55.232us      55.232us           0 B           0 B       4.00 KB       4.00 KB             1  \n",
      "                                           aten::conv2d         0.84%     203.339us        41.64%      10.021ms     189.080us       0.000us         0.00%       7.378ms     139.211us           0 B           0 B      42.58 MB           0 B            53  \n",
      "                                      aten::convolution         1.00%     241.061us        40.79%       9.818ms     185.244us       0.000us         0.00%       7.378ms     139.211us           0 B           0 B      42.58 MB           0 B            53  \n",
      "                                     aten::_convolution         1.88%     451.294us        39.79%       9.577ms     180.695us       0.000us         0.00%       7.378ms     139.211us           0 B           0 B      42.58 MB           0 B            53  \n",
      "                                Activity Buffer Request        19.28%       4.640ms        19.28%       4.640ms       4.640ms     124.832us         1.09%     124.832us     124.832us           0 B           0 B           0 B           0 B             1  \n",
      "                                       cudaLaunchKernel        10.32%       2.484ms        10.32%       2.484ms       9.779us       0.000us         0.00%       0.000us       0.000us           0 B           0 B           0 B           0 B           254  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 24.067ms\n",
      "Self CUDA time total: 11.472ms\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:04:03.798536714Z",
     "start_time": "2026-02-06T10:04:03.579744327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import pandas as pd\n",
    "from torchvision.models import resnet50, vit_b_16, efficientnet_b0, mobilenet_v3_small\n",
    "import time\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "\n",
    "class InferenceModeComparator:\n",
    "    def __init__(self, num_runs: int = 5):\n",
    "        self.num_runs = num_runs\n",
    "        self.results = []\n",
    "\n",
    "    def get_models_and_inputs(self) -> List[Tuple[str, torch.nn.Module, torch.Tensor]]:\n",
    "        models = []\n",
    "\n",
    "        resnet = resnet50().cuda()\n",
    "        resnet_input = torch.randn(32, 3, 224, 224).cuda()\n",
    "        models.append((\"ResNet50\", resnet, resnet_input))\n",
    "\n",
    "        vit = vit_b_16().cuda()\n",
    "        vit_input = torch.randn(32, 3, 224, 224).cuda()\n",
    "        models.append((\"ViT-B/16\", vit, vit_input))\n",
    "\n",
    "        effnet = efficientnet_b0().cuda()\n",
    "        effnet_input = torch.randn(32, 3, 224, 224).cuda()\n",
    "        models.append((\"EfficientNet-B0\", effnet, effnet_input))\n",
    "\n",
    "        mobilenet = mobilenet_v3_small().cuda()\n",
    "        mobilenet_input = torch.randn(32, 3, 224, 224).cuda()\n",
    "        models.append((\"MobileNetV3-Small\", mobilenet, mobilenet_input))\n",
    "\n",
    "        return models\n",
    "\n",
    "    def profile_no_grad(self, model: torch.nn.Module, input_tensor: torch.Tensor) -> Dict:\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        with profile(\n",
    "                activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                profile_memory=True,\n",
    "                record_shapes=True\n",
    "        ) as prof:\n",
    "            with record_function(\"no_grad_inference\"):\n",
    "                with torch.no_grad():\n",
    "                    _ = model(input_tensor)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "\n",
    "        stats = prof.key_averages()\n",
    "\n",
    "        total_cuda_time = 0\n",
    "        total_cpu_time = 0\n",
    "        total_cuda_memory = 0\n",
    "\n",
    "        for item in stats:\n",
    "            total_cuda_time += item.device_time_total\n",
    "            total_cpu_time += item.cpu_time_total\n",
    "\n",
    "            total_cuda_memory += item.self_device_memory_usage\n",
    "\n",
    "        return {\n",
    "            'cuda_time_us': total_cuda_time,\n",
    "            'cpu_time_us': total_cpu_time,\n",
    "            'cuda_memory_bytes': total_cuda_memory,\n",
    "            'wall_time_s': end_time - start_time\n",
    "        }\n",
    "\n",
    "    def profile_inference_mode(self, model: torch.nn.Module, input_tensor: torch.Tensor) -> Dict:\n",
    "        torch.cuda.synchronize()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        with profile(\n",
    "                activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "                profile_memory=True,\n",
    "                record_shapes=True\n",
    "        ) as prof:\n",
    "            with record_function(\"inference_mode\"):\n",
    "                with torch.inference_mode():\n",
    "                    _ = model(input_tensor)\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "\n",
    "        stats = prof.key_averages()\n",
    "\n",
    "        total_cuda_time = 0\n",
    "        total_cpu_time = 0\n",
    "        total_cuda_memory = 0\n",
    "\n",
    "        for item in stats:\n",
    "            total_cuda_time += item.device_time_total\n",
    "            total_cpu_time += item.cpu_time_total\n",
    "\n",
    "            total_cuda_memory += item.self_device_memory_usage\n",
    "\n",
    "        return {\n",
    "            'cuda_time_us': total_cuda_time,\n",
    "            'cpu_time_us': total_cpu_time,\n",
    "            'cuda_memory_bytes': total_cuda_memory,\n",
    "            'wall_time_s': end_time - start_time\n",
    "        }\n",
    "\n",
    "    def run_comparison(self):\n",
    "        models = self.get_models_and_inputs()\n",
    "\n",
    "        for model_name, model, input_tensor in models:\n",
    "            for run in range(self.num_runs):\n",
    "                if run == 0:\n",
    "                    with torch.no_grad():\n",
    "                        _ = model(input_tensor)\n",
    "                    torch.cuda.synchronize()\n",
    "\n",
    "                no_grad_metrics = self.profile_no_grad(model, input_tensor)\n",
    "\n",
    "                inference_mode_metrics = self.profile_inference_mode(model, input_tensor)\n",
    "\n",
    "                self.results.append({\n",
    "                    'model': model_name,\n",
    "                    'run': run + 1,\n",
    "                    'mode': 'no_grad',\n",
    "                    **no_grad_metrics\n",
    "                })\n",
    "\n",
    "                self.results.append({\n",
    "                    'model': model_name,\n",
    "                    'run': run + 1,\n",
    "                    'mode': 'inference_mode',\n",
    "                    **inference_mode_metrics\n",
    "                })\n",
    "\n",
    "            del model\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    def analyze_results(self) -> pd.DataFrame:\n",
    "        df = pd.DataFrame(self.results)\n",
    "\n",
    "        avg_df = df.groupby(['model', 'mode']).agg({\n",
    "            'cuda_time_us': 'mean',\n",
    "            'cpu_time_us': 'mean',\n",
    "            'cuda_memory_bytes': 'mean',\n",
    "            'wall_time_s': 'mean'\n",
    "        }).reset_index()\n",
    "\n",
    "        comparison_data = []\n",
    "\n",
    "        for model_name in avg_df['model'].unique():\n",
    "            model_data = avg_df[avg_df['model'] == model_name]\n",
    "\n",
    "            no_grad_row = model_data[model_data['mode'] == 'no_grad'].iloc[0]\n",
    "            inf_mode_row = model_data[model_data['mode'] == 'inference_mode'].iloc[0]\n",
    "\n",
    "            comparison_data.append({\n",
    "                'Model': model_name,\n",
    "                'no_grad_cuda_time': no_grad_row['cuda_time_us'],\n",
    "                'inference_mode_cuda_time': inf_mode_row['cuda_time_us'],\n",
    "                'cuda_time_diff_%': ((inf_mode_row['cuda_time_us'] - no_grad_row['cuda_time_us']) / no_grad_row[\n",
    "                    'cuda_time_us'] * 100),\n",
    "                'no_grad_cpu_time': no_grad_row['cpu_time_us'],\n",
    "                'inference_mode_cpu_time': inf_mode_row['cpu_time_us'],\n",
    "                'cpu_time_diff_%': ((inf_mode_row['cpu_time_us'] - no_grad_row['cpu_time_us']) / no_grad_row[\n",
    "                    'cpu_time_us'] * 100),\n",
    "                'no_grad_memory_MB': no_grad_row['cuda_memory_bytes'] / 1024 / 1024,\n",
    "                'inference_mode_memory_MB': inf_mode_row['cuda_memory_bytes'] / 1024 / 1024,\n",
    "                'memory_diff_%': ((inf_mode_row['cuda_memory_bytes'] - no_grad_row['cuda_memory_bytes']) / no_grad_row[\n",
    "                    'cuda_memory_bytes'] * 100) if no_grad_row['cuda_memory_bytes'] != 0 else 0,\n",
    "                'no_grad_wall_time_ms': no_grad_row['wall_time_s'] * 1000,\n",
    "                'inference_mode_wall_time_ms': inf_mode_row['wall_time_s'] * 1000,\n",
    "                'wall_time_diff_%': ((inf_mode_row['wall_time_s'] - no_grad_row['wall_time_s']) / no_grad_row[\n",
    "                    'wall_time_s'] * 100),\n",
    "            })\n",
    "\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "\n",
    "        return comparison_df, avg_df, df\n",
    "\n",
    "    def print_summary(self, comparison_df: pd.DataFrame):\n",
    "        print(comparison_df[\n",
    "            ['Model', 'no_grad_cuda_time', 'inference_mode_cuda_time', 'cuda_time_diff_%']].to_string(\n",
    "            index=False))\n",
    "\n",
    "        print(comparison_df[['Model', 'no_grad_memory_MB', 'inference_mode_memory_MB', 'memory_diff_%']].to_string(\n",
    "            index=False))\n",
    "\n",
    "        print(comparison_df[\n",
    "            ['Model', 'no_grad_wall_time_ms', 'inference_mode_wall_time_ms', 'wall_time_diff_%']].to_string(\n",
    "            index=False))\n",
    "\n",
    "\n"
   ],
   "id": "2343c5188c90cfe5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-06T10:06:38.330201332Z",
     "start_time": "2026-02-06T10:04:03.802495017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "comparator = InferenceModeComparator(num_runs=50)\n",
    "comparator.run_comparison()\n",
    "\n",
    "comparison_df, avg_df, raw_df = comparator.analyze_results()\n",
    "\n",
    "comparator.print_summary(comparison_df)\n",
    "\n",
    "comparison_df.to_csv('inference_mode_comparison.csv', index=False)\n",
    "\n",
    "comparison_df, avg_df, raw_df"
   ],
   "id": "408bd3c76902a307",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Model  no_grad_cuda_time  inference_mode_cuda_time  cuda_time_diff_%\n",
      "  EfficientNet-B0       3.771264e+05              3.771020e+05         -0.006480\n",
      "MobileNetV3-Small       8.782631e+04              8.780438e+04         -0.024972\n",
      "         ResNet50       1.006342e+06              1.005473e+06         -0.086349\n",
      "         ViT-B/16       4.537360e+06              4.538415e+06          0.023253\n",
      "            Model  no_grad_memory_MB  inference_mode_memory_MB  memory_diff_%\n",
      "  EfficientNet-B0            0.12207                   0.12207            0.0\n",
      "MobileNetV3-Small            0.12207                   0.12207            0.0\n",
      "         ResNet50            0.12207                   0.12207            0.0\n",
      "         ViT-B/16            0.12207                   0.12207            0.0\n",
      "            Model  no_grad_wall_time_ms  inference_mode_wall_time_ms  wall_time_diff_%\n",
      "  EfficientNet-B0             81.880479                    82.191329          0.379639\n",
      "MobileNetV3-Small             27.685623                    27.856741          0.618075\n",
      "         ResNet50            169.178948                   168.826618         -0.208259\n",
      "         ViT-B/16            865.848899                   865.771494         -0.008940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(               Model  no_grad_cuda_time  inference_mode_cuda_time  \\\n",
       " 0    EfficientNet-B0       3.771264e+05              3.771020e+05   \n",
       " 1  MobileNetV3-Small       8.782631e+04              8.780438e+04   \n",
       " 2           ResNet50       1.006342e+06              1.005473e+06   \n",
       " 3           ViT-B/16       4.537360e+06              4.538415e+06   \n",
       " \n",
       "    cuda_time_diff_%  no_grad_cpu_time  inference_mode_cpu_time  \\\n",
       " 0         -0.006480       91967.76426              92084.39496   \n",
       " 1         -0.024972       36113.06724              36202.56864   \n",
       " 2         -0.086349      179098.77398             178651.68460   \n",
       " 3          0.023253      872713.57940             872462.48304   \n",
       " \n",
       "    cpu_time_diff_%  no_grad_memory_MB  inference_mode_memory_MB  \\\n",
       " 0         0.126817            0.12207                   0.12207   \n",
       " 1         0.247837            0.12207                   0.12207   \n",
       " 2        -0.249633            0.12207                   0.12207   \n",
       " 3        -0.028772            0.12207                   0.12207   \n",
       " \n",
       "    memory_diff_%  no_grad_wall_time_ms  inference_mode_wall_time_ms  \\\n",
       " 0            0.0             81.880479                    82.191329   \n",
       " 1            0.0             27.685623                    27.856741   \n",
       " 2            0.0            169.178948                   168.826618   \n",
       " 3            0.0            865.848899                   865.771494   \n",
       " \n",
       "    wall_time_diff_%  \n",
       " 0          0.379639  \n",
       " 1          0.618075  \n",
       " 2         -0.208259  \n",
       " 3         -0.008940  ,\n",
       "                model            mode  cuda_time_us   cpu_time_us  \\\n",
       " 0    EfficientNet-B0  inference_mode  3.771020e+05   92084.39496   \n",
       " 1    EfficientNet-B0         no_grad  3.771264e+05   91967.76426   \n",
       " 2  MobileNetV3-Small  inference_mode  8.780438e+04   36202.56864   \n",
       " 3  MobileNetV3-Small         no_grad  8.782631e+04   36113.06724   \n",
       " 4           ResNet50  inference_mode  1.005473e+06  178651.68460   \n",
       " 5           ResNet50         no_grad  1.006342e+06  179098.77398   \n",
       " 6           ViT-B/16  inference_mode  4.538415e+06  872462.48304   \n",
       " 7           ViT-B/16         no_grad  4.537360e+06  872713.57940   \n",
       " \n",
       "    cuda_memory_bytes  wall_time_s  \n",
       " 0           128000.0     0.082191  \n",
       " 1           128000.0     0.081880  \n",
       " 2           128000.0     0.027857  \n",
       " 3           128000.0     0.027686  \n",
       " 4           128000.0     0.168827  \n",
       " 5           128000.0     0.169179  \n",
       " 6           128000.0     0.865771  \n",
       " 7           128000.0     0.865849  ,\n",
       "                  model  run            mode  cuda_time_us  cpu_time_us  \\\n",
       " 0             ResNet50    1         no_grad   1010500.958   172845.501   \n",
       " 1             ResNet50    1  inference_mode    999458.196   179464.192   \n",
       " 2             ResNet50    2         no_grad   1003849.582   182200.403   \n",
       " 3             ResNet50    2  inference_mode   1003121.928   175755.729   \n",
       " 4             ResNet50    3         no_grad   1003631.759   182172.291   \n",
       " ..                 ...  ...             ...           ...          ...   \n",
       " 395  MobileNetV3-Small   48  inference_mode     89533.101    38617.919   \n",
       " 396  MobileNetV3-Small   49         no_grad     89985.052    33592.246   \n",
       " 397  MobileNetV3-Small   49  inference_mode     89484.199    39407.433   \n",
       " 398  MobileNetV3-Small   50         no_grad     89905.603    33997.083   \n",
       " 399  MobileNetV3-Small   50  inference_mode     90145.056    34328.122   \n",
       " \n",
       "      cuda_memory_bytes  wall_time_s  \n",
       " 0               128000     0.178016  \n",
       " 1               128000     0.167840  \n",
       " 2               128000     0.168304  \n",
       " 3               128000     0.167062  \n",
       " 4               128000     0.168499  \n",
       " ..                 ...          ...  \n",
       " 395             128000     0.025554  \n",
       " 396             128000     0.025153  \n",
       " 397             128000     0.031170  \n",
       " 398             128000     0.030238  \n",
       " 399             128000     0.030028  \n",
       " \n",
       " [400 rows x 7 columns])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
